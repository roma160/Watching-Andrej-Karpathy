{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The second  part in the series (MLP -> Multilayer perceptron)\n",
    "\n",
    "https://youtu.be/TCH_1BHY58I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I will try to do in this notebook is rather trying to use Pytorch to train something\n",
    "\n",
    "The guy in the video basically is going to create an embedding (encoder -> decoder) network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's do some data import\n",
    "import utils.dataparse as dataparse\n",
    "\n",
    "project_folder = \"./\"\n",
    "\n",
    "with dataparse.get_file(\n",
    "    \"https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\",\n",
    "    project_folder + \"data/names.txt\"\n",
    ") as names:\n",
    "    words = names.read().split()\n",
    "\n",
    "words[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boilerplate from part1\n",
    "\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s: i + 1 for i, s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i: s for s, i in stoi.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting doing the math thingy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([228146, 3]), torch.Size([228146]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the training dataset:\n",
    "\n",
    "block_size = 3\n",
    "X, Y = [], []\n",
    "\n",
    "for w in words[:]:\n",
    "    # print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "\n",
    "        # print(''.join(itos[i] for i in context), '-->', itos[ix])\n",
    "\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)\n",
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9269,  1.4873],\n",
       "        [ 0.9007, -2.1055],\n",
       "        [ 0.6784, -1.2345],\n",
       "        [-0.0431, -1.6047],\n",
       "        [-0.7521,  1.6487],\n",
       "        [-0.3925, -1.4036],\n",
       "        [-0.7279, -0.5594],\n",
       "        [-0.7688,  0.7624],\n",
       "        [ 1.6423, -0.1596],\n",
       "        [-0.4974,  0.4396]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Doing the lookup table\n",
    "torch.manual_seed(42)\n",
    "\n",
    "C = torch.randn((len(stoi), 2))\n",
    "C[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.3925, -1.4036]), tensor([-0.3925, -1.4036]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(torch.tensor(5), num_classes=len(stoi)).float() @ C, C[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_layer_n = 100\n",
    "W1 = torch.randn((emb.shape[1] * emb.shape[2], second_layer_n))\n",
    "b1 = torch.randn(second_layer_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.0000, -0.0952, -0.8826, -0.1602,  0.7221,  1.0000,  0.9659, -0.8895,\n",
       "           1.0000, -0.9993,  0.8103, -0.1196, -0.9860,  0.3586,  0.9951,  1.0000,\n",
       "          -0.9555, -0.8892, -1.0000,  1.0000, -0.9851,  0.9975, -0.9984, -0.8343,\n",
       "           0.9383,  0.8768, -0.9999,  1.0000,  0.9995,  0.9906,  1.0000, -0.9658,\n",
       "           0.9926,  0.9999,  0.6609,  0.9991,  1.0000,  0.9936,  0.9975,  0.5316,\n",
       "          -1.0000, -0.9686, -1.0000,  0.9072,  1.0000,  0.4069,  0.9501,  0.9969,\n",
       "           0.7417, -0.8194,  0.9989,  0.8344,  0.3451, -0.4388,  0.2211,  1.0000,\n",
       "          -0.9987, -1.0000, -0.9843, -0.9982, -0.9986,  0.9999,  0.9976, -0.9404,\n",
       "          -0.9312,  0.8987,  0.3376, -0.9999,  0.9994,  1.0000,  0.9912,  1.0000,\n",
       "           0.5174,  0.9994,  1.0000,  0.7762,  0.9822, -0.9844, -0.9960,  0.9681,\n",
       "          -1.0000,  0.9978,  1.0000, -0.9975, -0.9995,  0.9835,  0.8506, -0.9970,\n",
       "          -0.9996,  0.9999, -0.9739,  0.8937, -0.9999,  1.0000, -0.9991,  1.0000,\n",
       "           0.9995, -0.9805,  0.9999, -0.9924]]),\n",
       " torch.Size([32, 100]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = torch.tanh(emb.view(emb.shape[0], -1) @ W1 + b1)\n",
    "h[:1], h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = torch.randn((second_layer_n, len(stoi)))\n",
    "b2 = torch.randn(len(stoi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = h @ W2 + b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is one way to compute the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = logits.exp()\n",
    "prob = counts / counts.sum(1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.7758)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -prob[torch.arange(prob.shape[0]), Y].log().mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But this one is better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.7758)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = F.cross_entropy(logits, Y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's combine forward and backwards pass together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To quicker reset things\n",
    "\n",
    "# Doing the lookup table\n",
    "torch.manual_seed(42)\n",
    "\n",
    "C = torch.randn((len(stoi), 2))\n",
    "\n",
    "second_layer_n = 100\n",
    "W1 = torch.randn((emb.shape[1] * emb.shape[2], second_layer_n))\n",
    "b1 = torch.randn(second_layer_n)\n",
    "W2 = torch.randn((second_layer_n, len(stoi)))\n",
    "b2 = torch.randn(len(stoi))\n",
    "\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2]\n",
    "\"\"\"\n",
    "    Fix to a\n",
    "    \"element 0 of tensors does not require grad and does not have a grad_fn\"\n",
    "    issue\n",
    "\"\"\"\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experementing with the learning rates\n",
    "\n",
    "lre = torch.linspace(-3, 0, 100)\n",
    "lrs = 10 ** lre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0813779830932617\n"
     ]
    }
   ],
   "source": [
    "lossi = []\n",
    "\n",
    "for i in range(10000):\n",
    "    # Batch construct\n",
    "    ix = torch.randint(0, X.shape[0], (32, ))\n",
    "\n",
    "    # Forwards pass\n",
    "    emb = C[X[ix]]\n",
    "    h = torch.tanh(emb.view(emb.shape[0], -1) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Y[ix])\n",
    "    # print(loss.item())\n",
    "\n",
    "    # # Backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # lr = lrs[i]\n",
    "    lr = 10 ** -2\n",
    "    for p in parameters:\n",
    "        p.data -= lr * p.grad\n",
    "\n",
    "    # Track stats\n",
    "    lossi.append(loss.item())\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes torch.Size([100]) and (10000,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\user\\projects\\python\\LearningML\\PyTorch\\Karpathy\\part2_mlp_way.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/user/projects/python/LearningML/PyTorch/Karpathy/part2_mlp_way.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m plt\u001b[39m.\u001b[39;49mplot(lre, lossi)\n",
      "File \u001b[1;32mc:\\Program Files\\Python\\Python39\\lib\\site-packages\\matplotlib\\pyplot.py:2757\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2755\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mplot)\n\u001b[0;32m   2756\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot\u001b[39m(\u001b[39m*\u001b[39margs, scalex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, scaley\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> 2757\u001b[0m     \u001b[39mreturn\u001b[39;00m gca()\u001b[39m.\u001b[39mplot(\n\u001b[0;32m   2758\u001b[0m         \u001b[39m*\u001b[39margs, scalex\u001b[39m=\u001b[39mscalex, scaley\u001b[39m=\u001b[39mscaley,\n\u001b[0;32m   2759\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m({\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m: data} \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Program Files\\Python\\Python39\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1632\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1391\u001b[0m \u001b[39mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1392\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1629\u001b[0m \u001b[39m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1630\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1631\u001b[0m kwargs \u001b[39m=\u001b[39m cbook\u001b[39m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[39m.\u001b[39mLine2D)\n\u001b[1;32m-> 1632\u001b[0m lines \u001b[39m=\u001b[39m [\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_lines(\u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39mdata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)]\n\u001b[0;32m   1633\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines:\n\u001b[0;32m   1634\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32mc:\\Program Files\\Python\\Python39\\lib\\site-packages\\matplotlib\\axes\\_base.py:312\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m     this \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m],\n\u001b[0;32m    311\u001b[0m     args \u001b[39m=\u001b[39m args[\u001b[39m1\u001b[39m:]\n\u001b[1;32m--> 312\u001b[0m \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_plot_args(this, kwargs)\n",
      "File \u001b[1;32mc:\\Program Files\\Python\\Python39\\lib\\site-packages\\matplotlib\\axes\\_base.py:498\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[0;32m    495\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes\u001b[39m.\u001b[39myaxis\u001b[39m.\u001b[39mupdate_units(y)\n\u001b[0;32m    497\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[1;32m--> 498\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx and y must have same first dimension, but \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    499\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhave shapes \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    500\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39mor\u001b[39;00m y\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx and y can be no greater than 2D, but have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    502\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mshapes \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes torch.Size([100]) and (10000,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lre, lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2942, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X]\n",
    "h = torch.tanh(emb.view(emb.shape[0], -1) @ W1 + b1)\n",
    "logits = h @ W2 + b2\n",
    "loss = F.cross_entropy(logits, Y)\n",
    "loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
